{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\anaconda3\\envs\\BERT_Practice\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料集介紹\n",
    "[**IMDB Dataset of 50K Movie Reviews**](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)  \n",
    "資料集描述：取一段電影評論 (review)，每筆評論會有對應的評價(sentiment)，表示好評或負評  \n",
    "總資料數：50000  \n",
    "好評、負評比 = 1 : 1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料集處理 (單純的 pandas 切分)\n",
    "預計將 訓練 : 驗證 : 測試 切成 60 : 20 : 20  \n",
    "配合[原始範例程式碼](https://gist.github.com/vincenttzc/ceaa4aca25e53cb8da195f07e7d0af92#file-trainer_train_predict-py)，這邊用 pandas 把資料分成兩份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# 把 \"sentiment\" 標籤的 \"positive\"、\"negative\" 換成 \"1\"、\"0\"\n",
    "for i in range(len(df['sentiment'])):\n",
    "    if df.at[i, 'sentiment'] == 'positive':\n",
    "        df.at[i, 'sentiment'] = 1\n",
    "    else:\n",
    "        df.at[i, 'sentiment'] = 0\n",
    " \n",
    "# 先根據分類 (0、1) 分成兩群，以便切分後的以便切分後的訓練、測試集的正、反資料集保持相同\n",
    "groups = df.groupby(df.sentiment)\n",
    "data_positive = groups.get_group(1)\n",
    "data_negative = groups.get_group(0)\n",
    "\n",
    "# 用 sample 進行抽樣 (講白話就是隨機打亂)\n",
    "data_positive = data_positive.sample(frac=1.0)\n",
    "data_negative = data_negative.sample(frac=1.0)\n",
    "\n",
    "# 用 index 去切分訓練、資料集，再各自將正、反資料結合並存取\n",
    "test_positive = data_positive.iloc[20000:, :]\n",
    "test_negative = data_negative.iloc[20000:, :]\n",
    "test_data = pd.concat([test_positive, test_negative], axis = 0, ignore_index=True).sample(frac=1)\n",
    "train_positive = data_positive.iloc[:20000, :]\n",
    "train_negative = data_negative.iloc[:20000, :]\n",
    "train_data = pd.concat([train_positive, train_negative], axis = 0, ignore_index=True).sample(frac=1)\n",
    "\n",
    "test_data.to_csv('test.csv', index = None)\n",
    "train_data.to_csv('train.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理\n",
    "1. BERT cased vs. BERT uncased  \n",
    "   BERT cased: 字母保留原樣  \n",
    "   BERT uncased: 在做 WordPiece tokenization 前，會先將所有字母變小寫 (lowercased)、附加符號 (Accent markers) 拔掉  \n",
    "2. BertModel vs. BertForSequenceClassification  \n",
    "   BertModel: 基本 BERT 模型  \n",
    "   BertForSequenceClassification: 針對序列 (文本) 分類做過 Fine-tune 的 BERT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Define pretrained tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2) # num_labels: 分類類別數量\n",
    "\n",
    "# ----- 1. Preprocess data -----#\n",
    "# Preprocess data\n",
    "X = list(data[\"review\"])\n",
    "y = list(data[\"sentiment\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25)          # 用 sklearn 將 train data 切分成訓練、驗證資料集，test_size = 0.25 表示 test 佔 25%\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立 Model\n",
    "* [Train](https://huggingface.co/docs/transformers/training#train)\n",
    "  * [```Trainer```](https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/trainer#transformers.Trainer)  \n",
    "    一些常用參數如下：\n",
    "    * ```model```: 使用的 Model\n",
    "    * ```args```: 訓練的相關參數\n",
    "    * ```train_dataset```: 訓練資料集\n",
    "    * ```eval_dataset```: 驗證資料集\n",
    "    * ```compute_metrics```: 設定評估指標\n",
    "    * ```callbacks```: (資料型態：list) 設定訓練模型過程中的觸發事件\n",
    "      > Early Stopping:  \n",
    "      > 參考資料：[連結](https://clay-atlas.com/blog/2020/09/29/pytorch-cn-early-stopping-code/)  \n",
    "      > 為了預防 Overfitting，我們可以嘗試在模型失去泛化性前就先停止訓練  \n",
    "      > ```early_stopping_patience```: 設定 loss (accuracy) 連續變差幾次就停止訓練\n",
    "  * [```TrainingArguments```](https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/trainer#transformers.TrainingArguments)  \n",
    "    一些常用的參數如下：  \n",
    "    * ```output_dir```: 存放模型訓練期間可能產生的檔案 (如：checkpoint, log 等等) 的路徑\n",
    "    * ```evaluation_strategy```: 做評估的頻率單位\n",
    "      * ```\"no\"```: 不在訓練期間做評估\n",
    "      * ```\"steps\"```: 訓練時，每過 ```eval_steps``` 做一次評估\n",
    "      * ```epoch```: 每個 epoch 結束做一次評估\n",
    "    * ```eval_steps```: 每隔多少 steps 做一次評估\n",
    "    * ```per_device_train_batch_size```: 每個 GPU/TPU core/CPU 訓練的 batch size\n",
    "    * ```per_device_eval_batch_size```: 每個 GPU/TPU core/CPU 評估的 batch size\n",
    "    * ```num_train_epochs```: 訓練的 Epoch 數\n",
    "    * ```seed```: Random seed (預設為 42)，以確保模型的再現性 (reproducibility)\n",
    "    * ```load_best_model_at_end```: 訓練結束後是否載入最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\anaconda3\\envs\\BERT_Practice\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 30000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\n",
      "  Number of trainable parameters = 109483778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfdacb1199a433a9ff0237bcfcdeabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4278, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75fec1a3d8b442f82839242fd9ae352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-500\n",
      "Configuration saved in output\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4498305320739746, 'eval_accuracy': 0.8552, 'eval_precision': 0.7842729019859065, 'eval_recall': 0.9797919167667066, 'eval_f1': 0.8711972958548301, 'eval_runtime': 150.4779, 'eval_samples_per_second': 66.455, 'eval_steps_per_second': 8.307, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3492, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311c9e6926a94e7fa832f1e5824fb34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-1000\n",
      "Configuration saved in output\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29226070642471313, 'eval_accuracy': 0.9068, 'eval_precision': 0.9155764513491415, 'eval_recall': 0.8961584633853541, 'eval_f1': 0.9057633973710818, 'eval_runtime': 151.3169, 'eval_samples_per_second': 66.086, 'eval_steps_per_second': 8.261, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-1000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3388, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389032c2649d437296aa5d7aea631fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-1500\n",
      "Configuration saved in output\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23939402401447296, 'eval_accuracy': 0.9134, 'eval_precision': 0.8927756653992396, 'eval_recall': 0.9395758303321329, 'eval_f1': 0.9155780853967634, 'eval_runtime': 151.4986, 'eval_samples_per_second': 66.007, 'eval_steps_per_second': 8.251, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-1500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3097, 'learning_rate': 4.111111111111111e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97859b23404a446b846257e30080269b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-2000\n",
      "Configuration saved in output\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36775365471839905, 'eval_accuracy': 0.9056, 'eval_precision': 0.9488485385296723, 'eval_recall': 0.85734293717487, 'eval_f1': 0.9007778011351693, 'eval_runtime': 150.9938, 'eval_samples_per_second': 66.228, 'eval_steps_per_second': 8.278, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-2000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3015, 'learning_rate': 3.888888888888889e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2d91f794fb41c8b0a9d023ef0e3f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-2500\n",
      "Configuration saved in output\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28231674432754517, 'eval_accuracy': 0.9217, 'eval_precision': 0.9138032593756136, 'eval_recall': 0.9311724689875951, 'eval_f1': 0.9224061044495094, 'eval_runtime': 151.7783, 'eval_samples_per_second': 65.886, 'eval_steps_per_second': 8.236, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-2500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.309, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b8f1616d1e4132a408b05aad448128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-3000\n",
      "Configuration saved in output\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2480802685022354, 'eval_accuracy': 0.926, 'eval_precision': 0.92008681925809, 'eval_recall': 0.9329731892757103, 'eval_f1': 0.9264851976952115, 'eval_runtime': 151.5164, 'eval_samples_per_second': 65.999, 'eval_steps_per_second': 8.25, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-3000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2875, 'learning_rate': 3.444444444444445e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b1d35d6a41451ca7187e2c6eb537c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-3500\n",
      "Configuration saved in output\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23376521468162537, 'eval_accuracy': 0.9324, 'eval_precision': 0.9242245779348253, 'eval_recall': 0.9419767907162865, 'eval_f1': 0.9330162504954419, 'eval_runtime': 151.9746, 'eval_samples_per_second': 65.8, 'eval_steps_per_second': 8.225, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-3500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2299, 'learning_rate': 3.222222222222223e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafd20a267b1436491b8314150ae34f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-4000\n",
      "Configuration saved in output\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29942676424980164, 'eval_accuracy': 0.9362, 'eval_precision': 0.9434499593165175, 'eval_recall': 0.9279711884753902, 'eval_f1': 0.9356465604196086, 'eval_runtime': 152.0294, 'eval_samples_per_second': 65.777, 'eval_steps_per_second': 8.222, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-4000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1886, 'learning_rate': 3e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5e347d095f41e19cfa0b952dfc6a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-4500\n",
      "Configuration saved in output\\checkpoint-4500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39853063225746155, 'eval_accuracy': 0.9195, 'eval_precision': 0.8829223744292237, 'eval_recall': 0.9671868747499, 'eval_f1': 0.9231356822304974, 'eval_runtime': 151.3352, 'eval_samples_per_second': 66.078, 'eval_steps_per_second': 8.26, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-4500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1815, 'learning_rate': 2.777777777777778e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77955ce1b9f4b37aaa12d50ad1f437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-5000\n",
      "Configuration saved in output\\checkpoint-5000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30053597688674927, 'eval_accuracy': 0.9339, 'eval_precision': 0.9378154653745205, 'eval_recall': 0.9293717486994798, 'eval_f1': 0.9335745151241082, 'eval_runtime': 151.6604, 'eval_samples_per_second': 65.937, 'eval_steps_per_second': 8.242, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-5000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1828, 'learning_rate': 2.5555555555555554e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f578069798384352b1a45166d1680769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-5500\n",
      "Configuration saved in output\\checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28743287920951843, 'eval_accuracy': 0.9334, 'eval_precision': 0.9365175332527207, 'eval_recall': 0.9297719087635054, 'eval_f1': 0.9331325301204819, 'eval_runtime': 151.1238, 'eval_samples_per_second': 66.171, 'eval_steps_per_second': 8.271, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-5500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2094, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdc2d45a7ae4c45a1b714985c773556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-6000\n",
      "Configuration saved in output\\checkpoint-6000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28433603048324585, 'eval_accuracy': 0.9371, 'eval_precision': 0.9267435045907404, 'eval_recall': 0.9491796718687475, 'eval_f1': 0.9378274191954137, 'eval_runtime': 150.7835, 'eval_samples_per_second': 66.32, 'eval_steps_per_second': 8.29, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-6000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.176, 'learning_rate': 2.111111111111111e-05, 'epoch': 1.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f721b5faee5451a917d4a0aa3f9e16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-6500\n",
      "Configuration saved in output\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29671210050582886, 'eval_accuracy': 0.9308, 'eval_precision': 0.9450186027284002, 'eval_recall': 0.9147659063625451, 'eval_f1': 0.9296461976413177, 'eval_runtime': 151.1854, 'eval_samples_per_second': 66.144, 'eval_steps_per_second': 8.268, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-6500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1845, 'learning_rate': 1.888888888888889e-05, 'epoch': 1.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9a94b8a8ce41b4b71aa20442f943d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-7000\n",
      "Configuration saved in output\\checkpoint-7000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2489902824163437, 'eval_accuracy': 0.9399, 'eval_precision': 0.9354327589621707, 'eval_recall': 0.9449779911964786, 'eval_f1': 0.9401811486015726, 'eval_runtime': 151.2673, 'eval_samples_per_second': 66.108, 'eval_steps_per_second': 8.264, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-7000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1836, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fae696609a4361b367aa6aa7b8638f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-7500\n",
      "Configuration saved in output\\checkpoint-7500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2984444797039032, 'eval_accuracy': 0.9312, 'eval_precision': 0.903558052434457, 'eval_recall': 0.9653861544617847, 'eval_f1': 0.9334494099438962, 'eval_runtime': 152.8904, 'eval_samples_per_second': 65.406, 'eval_steps_per_second': 8.176, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-7500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0729, 'learning_rate': 1.4444444444444444e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3cec02af2148a899cfb57ab1003ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-8000\n",
      "Configuration saved in output\\checkpoint-8000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34779030084609985, 'eval_accuracy': 0.934, 'eval_precision': 0.9187258687258687, 'eval_recall': 0.9521808723489396, 'eval_f1': 0.9351542542739241, 'eval_runtime': 152.4388, 'eval_samples_per_second': 65.6, 'eval_steps_per_second': 8.2, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-8000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0842, 'learning_rate': 1.2222222222222222e-05, 'epoch': 2.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7c3490aa446a2b2ae42fdce4e8391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-8500\n",
      "Configuration saved in output\\checkpoint-8500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32888126373291016, 'eval_accuracy': 0.9387, 'eval_precision': 0.9378869582584382, 'eval_recall': 0.9395758303321329, 'eval_f1': 0.9387306346826587, 'eval_runtime': 152.4213, 'eval_samples_per_second': 65.608, 'eval_steps_per_second': 8.201, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-8500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0711, 'learning_rate': 1e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f701416a1a47c690311eab5d9a142d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-9000\n",
      "Configuration saved in output\\checkpoint-9000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3601808547973633, 'eval_accuracy': 0.9369, 'eval_precision': 0.9307555730913395, 'eval_recall': 0.9439775910364145, 'eval_f1': 0.9373199562928379, 'eval_runtime': 152.8821, 'eval_samples_per_second': 65.41, 'eval_steps_per_second': 8.176, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-9000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0861, 'learning_rate': 7.777777777777777e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83b3eeefef7407582c91190a43db05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-9500\n",
      "Configuration saved in output\\checkpoint-9500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3387373089790344, 'eval_accuracy': 0.9393, 'eval_precision': 0.9338075479154317, 'eval_recall': 0.9455782312925171, 'eval_f1': 0.9396560294263844, 'eval_runtime': 153.1327, 'eval_samples_per_second': 65.303, 'eval_steps_per_second': 8.163, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-9500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.079, 'learning_rate': 5.555555555555556e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbd564346204735ad6af49810c57ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10000\n",
      "Configuration saved in output\\checkpoint-10000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3300251364707947, 'eval_accuracy': 0.9384, 'eval_precision': 0.9307904050334251, 'eval_recall': 0.9471788715486195, 'eval_f1': 0.9389131297104324, 'eval_runtime': 152.6972, 'eval_samples_per_second': 65.489, 'eval_steps_per_second': 8.186, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-10000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0894, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663f3423d15349df908545e8d3e0fb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-10500\n",
      "Configuration saved in output\\checkpoint-10500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3173092305660248, 'eval_accuracy': 0.9409, 'eval_precision': 0.9445228969134557, 'eval_recall': 0.9367747098839536, 'eval_f1': 0.9406328478151683, 'eval_runtime': 151.9678, 'eval_samples_per_second': 65.803, 'eval_steps_per_second': 8.225, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-10500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.075, 'learning_rate': 1.1111111111111112e-06, 'epoch': 2.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f23e273d51494a839e3be5617c6eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output\\checkpoint-11000\n",
      "Configuration saved in output\\checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3215979337692261, 'eval_accuracy': 0.939, 'eval_precision': 0.9296905601253427, 'eval_recall': 0.949779911964786, 'eval_f1': 0.9396278701504354, 'eval_runtime': 152.0617, 'eval_samples_per_second': 65.763, 'eval_steps_per_second': 8.22, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output\\checkpoint-11000\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output\\checkpoint-3500 (score: 0.23376521468162537).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7705.753, 'train_samples_per_second': 11.68, 'train_steps_per_second': 1.46, 'train_loss': 0.19825113050672744, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11250, training_loss=0.19825113050672744, metrics={'train_runtime': 7705.753, 'train_samples_per_second': 11.68, 'train_steps_per_second': 1.46, 'train_loss': 0.19825113050672744, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- 2. Fine-tune pretrained model -----#\n",
    "# Define Trainer parameters\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    seed=0,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=16)],\n",
    ")\n",
    "\n",
    "# Train pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a767d87ce95a4dbb82dd1011f0ca630b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- 3. Predict -----#\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_test = list(test_data[\"review\"])\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "test_dataset = Dataset(X_test_tokenized)\n",
    "\n",
    "# Load trained model\n",
    "model_path = \"output/checkpoint-11000\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# Define test trainer\n",
    "test_trainer = Trainer(model)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9734\n"
     ]
    }
   ],
   "source": [
    "y_ori = np.array(test_data[\"sentiment\"])\n",
    "cnt = 0\n",
    "y_len = len(y_pred)\n",
    "\n",
    "for i in range(y_len):\n",
    "    cnt += 1 if (y_ori[i] == y_pred[i]) else 0\n",
    "\n",
    "print(\"Accuracy: \", float(cnt / y_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('BERT_Practice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "684b83e2f83316061361748e41b2620a10a3e9a8f2545480c20c18cf426689ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
